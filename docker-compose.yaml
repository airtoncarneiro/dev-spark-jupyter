services:
  master:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: my-spark:3.5.0
    environment:
      - SPARK_MODE=master
    ports:
      - '8080:8080'
    networks:
      - spark-net
    command: ["/opt/bitnami/scripts/spark/run.sh"]

  worker:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: my-spark:3.5.0
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - master
    networks:
      - spark-net
    command: ["/opt/bitnami/scripts/spark/run.sh"]

  history-server:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: my-spark:3.5.0
    environment:
      - SPARK_MODE=history-server
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/bitnami/spark/logs
      - SPARK_HISTORY_FS_UPDATE_INTERVAL=10s
    ports:
      - '18080:18080'
    volumes:
      - ./logs:/opt/bitnami/spark/logs

    command: ["/opt/bitnami/spark/sbin/start-history-server.sh"]
    depends_on:
      - master
    networks:
      - spark-net
  
  jupyter:
    build:
      context: .
      dockerfile: dockerfile-jupyter
    image: my-notebook:pyspark-3.5.0
    environment:
      - JUPYTER_ENABLE_LAB=yes
    ports:
      - "8888:8888"
    volumes:
      - ./notebooks:/home/jovyan/work/notebooks
      - ./logs:/home/jovyan/work/logs
    networks:
      - spark-net
    depends_on:
      - master

networks:
  spark-net:
    driver: bridge

volumes:
  spark-worker-data:
