services:
  spark:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: bitnami/spark:3.5.1
    environment:
      - SPARK_MODE=master
    ports:
      - '8080:8080'
    networks:
      - spark-net
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./scripts:/opt/bitnami/spark/scripts
    command: ["/opt/bitnami/scripts/spark/run.sh"]

  spark-worker:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: bitnami/spark:3.5.1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - spark
    networks:
      - spark-net
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./scripts:/opt/bitnami/spark/scripts
    command: ["/opt/bitnami/scripts/spark/run.sh"]

  spark-history-server:
    build:
      context: .
      dockerfile: dockerfile-spark
    image: bitnami/spark:3.5.1
    container_name: spark-history-server
    environment:
      - SPARK_MODE=history-server
      # - SPARK_HISTORY_SERVER_PORT=18080
      # - SPARK_HISTORY_UI_PORT=18080
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=/opt/bitnami/spark/logs
      # - SPARK_DAEMON_MEMORY=5g
      # - SPARK_EVENTLOG_ENABLED=true
      # - SPARK_DAEMON_MEMORY=10g
      # - SPARK_HISTORY_RETAINEDAPPLICATIONS=100
      # - SPARK_HISTORY_UI_MAXAPPLICATIONS=500
      # - SPARK_HISTORY_STORE_MAXDISKUSAGE=100g
      # - SPARK_HISTORY_FS_CLEANER_ENABLED=true
      # - SPARK_HISTORY_FS_CLEANER_INTERVAL=8h
      # - SPARK_HISTORY_FS_CLEANER_MAXAGE=5d
      # - SPARK_HISTORY_FS_UPDATE_INTERVAL=10s
    ports:
      - '18080:18080'
    volumes:
      - ./data:/opt/bitnami/spark/data
      - ./logs:/opt/bitnami/spark/logs

    command: ["/opt/bitnami/spark/sbin/start-history-server.sh"]
    depends_on:
      - spark
    networks:
      - spark-net
networks:
  spark-net:
    driver: bridge

volumes:
  spark-data:
  spark-worker-data:
